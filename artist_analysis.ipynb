{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load clustered dataset\n",
    "df = pd.read_csv(\"dataset_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Expand artists column to handle collabs\n",
    "df['artists'] = df['artists'].str.split(', ')\n",
    "df_exploded = df.explode('artists')\n",
    "\n",
    "# Step 2: Compute average popularity_index per artist\n",
    "# AND count of unique songs they contributed to\n",
    "artist_popularity = (\n",
    "    df_exploded\n",
    "    .groupby('artists')\n",
    "    .agg(\n",
    "        avg_popularity=('popularity_index', 'mean'),\n",
    "        unique_tracks=('spotify_id', 'nunique')\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(columns={'artists': 'artist'})\n",
    ")\n",
    "\n",
    "# Step 3: Compute penalty factor based on unique_tracks\n",
    "alpha = 20  # can tune this: higher = more penalty for fewer tracks\n",
    "artist_popularity['penalty'] = (\n",
    "    artist_popularity['unique_tracks'] / (artist_popularity['unique_tracks'] + alpha)\n",
    ")\n",
    "\n",
    "# Step 4: Adjust avg_popularity using the penalty\n",
    "artist_popularity['adjusted_popularity'] = (\n",
    "    artist_popularity['avg_popularity'] * artist_popularity['penalty']\n",
    ")\n",
    "\n",
    "# Step 5: Normalize adjusted_popularity to a 0â€“1 scale\n",
    "min_score = artist_popularity['adjusted_popularity'].min()\n",
    "max_score = artist_popularity['adjusted_popularity'].max()\n",
    "artist_popularity['normalized_popularity'] = (\n",
    "    (artist_popularity['adjusted_popularity'] - min_score) /\n",
    "    (max_score - min_score)\n",
    ")\n",
    "\n",
    "# Step 6: Classify tiers using normalized values\n",
    "quantiles = artist_popularity['normalized_popularity'].quantile([0.85, 0.5])\n",
    "q80 = quantiles[0.85]\n",
    "q50 = quantiles[0.5]\n",
    "\n",
    "def classify_tier(score):\n",
    "    if score >= q80:\n",
    "        return \"Headliner\"\n",
    "    elif score >= q50:\n",
    "        return \"Co-Headliner\"\n",
    "    else:\n",
    "        return \"Support\"\n",
    "\n",
    "artist_popularity['lineup_tier'] = artist_popularity['normalized_popularity'].apply(classify_tier)\n",
    "\n",
    "# Step 7: Merge classification back to exploded song-artist data (optional)\n",
    "df_final = df_exploded.merge(\n",
    "    artist_popularity[['artist', 'avg_popularity', 'adjusted_popularity', 'normalized_popularity', 'lineup_tier']],\n",
    "    left_on='artists',\n",
    "    right_on='artist',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_final.to_csv(\"us_lineup_tiers.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Optional: Save final artist list\n",
    "artist_popularity.to_csv(\"artist_lineup_classification.csv\", index=False)\n",
    "df_final.to_csv(\"clustered_data_with_lineup_tiers.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
