{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Step 1: Read your dataset\n",
    "df = pd.read_csv(\"data/1_filtered_us_artists_2024_2025.csv\")  # or pd.read_excel() if using Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snapshot_date'] = pd.to_datetime(df['snapshot_date'])\n",
    "\n",
    "# 3. Compute the total number of unique days in the dataset (for normalization)\n",
    "total_days = df['snapshot_date'].nunique()\n",
    "\n",
    "# 4. Extract primary_artist by splitting the 'artists' column on the comma and taking the first value\n",
    "df['primary_artist'] = df['artists'].apply(lambda x: x.split(',')[0].strip())\n",
    "\n",
    "# 5. Compute aggregated track-level metrics for each unique song (spotify_id)\n",
    "#    - avg_daily_rank: mean of daily_rank values\n",
    "#    - avg_popularity: mean of popularity values\n",
    "#    - days_in_top50: count of days the song appears in the Top 50\n",
    "#    - primary_artist: first occurrence (used later for artist info, if needed)\n",
    "track_metrics = df.groupby('spotify_id').agg(\n",
    "    avg_daily_rank=('daily_rank', 'mean'),\n",
    "    avg_popularity=('popularity', 'mean'),\n",
    "    days_in_top50=('snapshot_date', 'count'),\n",
    "    primary_artist=('primary_artist', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# 6. Compute the normalized base index for each track (0-1 scale)\n",
    "#    Formula:\n",
    "#    popularity_index = (days_in_top50 / total_days) * ((51 - avg_daily_rank) / 50) * (avg_popularity / 100)\n",
    "track_metrics['popularity_index'] = (\n",
    "    (track_metrics['days_in_top50'] / total_days) *\n",
    "    ((51 - track_metrics['avg_daily_rank']) / 50) *\n",
    "    (track_metrics['avg_popularity'] / 100)\n",
    ")\n",
    "\n",
    "# 7. To preserve all additional columns, take the first occurrence of each unique song from the original dataset\n",
    "first_occurrence = df.drop_duplicates(subset=['spotify_id']).copy()\n",
    "\n",
    "# 8. Merge the computed popularity_index back into the first_occurrence DataFrame\n",
    "final_df = first_occurrence.merge(\n",
    "    track_metrics[['spotify_id', 'popularity_index']],\n",
    "    on='spotify_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 9. Save the final DataFrame to CSV\n",
    "final_df.to_csv(\"us_popularity_index.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This added popularity index which is calculated based \n",
    "popularity_index = 0.5 * avg_popularity \n",
    "                 + 0.3 * mean_inv_rank \n",
    "                 + 0.2 * days_in_top50\n",
    "\n",
    "Why this formula?\n",
    "\n",
    "avg_popularity captures fan engagement on Spotify (0–100 scale)\n",
    "\n",
    "mean_inv_rank reflects chart strength (inverted rank → higher = better)\n",
    "\n",
    "days_in_top50 represents chart longevity (how long it stayed relevant)\n",
    "\n",
    "We weight popularity most (50%) because it best reflects streaming success, but we still value chart rank and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
